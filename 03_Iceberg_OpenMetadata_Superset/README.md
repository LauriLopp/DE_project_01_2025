
# ğŸ“Š Part 3 â€” Data Governance & Visualization

This part of the project focuses on implementing data governance and visualization using:

- **Apache Iceberg**
- **ClickHouse**
- **OpenMetadata**
- **Apache Superset**

---

## ğŸš€ Project Overview

For Project 3 we added minio as the object storage for the data that is queried through API's. 
Data pipeline in a simplified form:

1. Elering Price API
2. Minio with Iceberg to ensure rollbacks & consistent reads across snapshots
3. Clickhouse as the main database
4. Apache Superset to visualise data

All data is still automated via Apache Airflow and DBT.

---

## ğŸ› ï¸ Setup & Installation

1. **Install [Tailscale](https://tailscale.com/)**: Sign in to Tailscale with the Google account or invite link provided by the team.
2. **Obtain secrets**: Get the shared `.env.local` file from the team. Place it alongside `docker-compose.yml` inside `02_Airflow_ClickHouse_dbt/` before starting any containers.
The file can be found from [Google Drive](https://drive.google.com/file/d/1_C8yHceYJq4tOPXwc69b1QlV-fdz3qt6/view?usp=sharing) and is directly available to course lectors. The peer graders and other interested parties must request access and **provide well explained reason** to obtain the access.
3. **Clone or update the project**:
  - Fresh setup: `git clone https://github.com/LauriLopp/DE_project_2025.git`
  - Existing clone: `git pull` to fetch the latest changes.
4. **Change directory**: `cd DE_project_2025/02_Airflow_ClickHouse_dbt`
5. **Start the stack**: `docker compose up --build -d`
6. **Access Airflow**: open `http://localhost:8080`, log in with username `airflow` and password `airflow`.
7. **Enable Main DAG**: turn on the `continuous_ingestion_pipeline` DAG and confirm the tasks progress to running state.
8. **Enable Historical DAG**: turn on the `backfill_historical_data` DAG and confirm the tasks progress to running state.
9  **Verify Metadata**: Open http://localhost:8585/ and log in with credentials: admin@open-metadata.org/admin   
10. **Verify that data is in Minio (Object Storage)**: Open `http://localhost:9001/login` , log in with credentials minioadmin/minioadmin
11. **Access Apache Superset UI**: open `http://localhost:8088`, login with credentials: admin/admin
12. **Verify data**: Navigate to dashboard for data visualisations. See screenshots in Example Queries & Dashboards

---

## ğŸ“ Project Structure

```
03_Iceberg_OpenMetadata_Superset/
â”œâ”€â”€ .env.local                          # (User-provided) Contains secret tokens and credentials
â”œâ”€â”€ clickhouse-init/                    # Scripts to initialize ClickHouse on first run
â”‚   â”œâ”€â”€ 01_roles.sql                    # Role definitions for ClickHouse access control
â”‚   â”œâ”€â”€ 02_users.sql                    # User creation scripts with role assignments
â”‚   â””â”€â”€ 04_grants.sql                   # Grant statements for database permissions
â”œâ”€â”€ cloudbeaver-init/                   # Pre-configured connection settings for CloudBeaver UI
â”‚   â”œâ”€â”€ .dbeaver/
â”‚   â”‚   â””â”€â”€ data-sources.json           # CloudBeaver data source configuration
â”‚   â””â”€â”€ initial-data-sources.json       # Initial connection settings template
â”œâ”€â”€ config/                             # ClickHouse user and profile configurations
â”‚   â””â”€â”€ users.d/
â”‚       â”œâ”€â”€ default-user.xml            # Default user configuration
â”‚       â””â”€â”€ temp_admin.xml              # Temporary admin user configuration
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ backfill_historical_data.py     # DAG for backfilling historical Iceberg data
â”‚   â””â”€â”€ home_assistant_continuous_raw.py # Main Airflow DAG with OpenMetadata sync
â”œâ”€â”€ data/                               # Mounted volume for data exchange
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_packages/                   # (Generated) Installed dbt packages
â”‚   â”œâ”€â”€ macros/
â”‚   â”‚   â””â”€â”€ expression_is_true_clickhouse.sql # Custom generic test for ClickHouse
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ marts/                      # Gold layer: Dimensional and fact models
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_device.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_location.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_time.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ fact_heating_energy_usage.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml              # Tests and descriptions for mart layer
â”‚   â”‚   â”œâ”€â”€ staging/                    # Silver layer: Cleaned and standardized views
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_device.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_iot_data.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_location.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_price_data.sql
â”‚   â”‚   â”‚   â””â”€â”€ stg_weather_data.sql
â”‚   â”‚   â”œâ”€â”€ views/                      # Access-controlled views for role-based access
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.yml              # Tests and descriptions for views
â”‚   â”‚   â”‚   â”œâ”€â”€ v_heating_energy_full_access.sql
â”‚   â”‚   â”‚   â””â”€â”€ v_heating_energy_limited_access.sql
â”‚   â”‚   â””â”€â”€ sources.yml                 # Defines Bronze layer sources for dbt
â”‚   â”œâ”€â”€ seeds/
â”‚   â”‚   â””â”€â”€ estonian_holidays.csv       # Seed data for public holidays
â”‚   â”œâ”€â”€ .user.yml                       # (Generated) dbt user configuration
â”‚   â”œâ”€â”€ dbt_project.yml                 # Main dbt project configuration file
â”‚   â”œâ”€â”€ package-lock.yml                # Lockfile for dbt package versions
â”‚   â”œâ”€â”€ packages.yml                    # External dbt package dependencies
â”‚   â”œâ”€â”€ profiles.yml                    # Database connection profiles for dbt
â”‚   â””â”€â”€ selectors.yml                   # Definitions for selecting subsets of models
â”œâ”€â”€ device_location_data/               # Static CSVs mounted into ClickHouse for seeding
â”‚   â”œâ”€â”€ device_data.csv
â”‚   â””â”€â”€ location_data.csv
â”œâ”€â”€ logs/                               # (Generated) Airflow task logs
â”œâ”€â”€ openmetadata-init/                  # Automated OpenMetadata bootstrapping scripts
â”‚   â”œâ”€â”€ bootstrap_openmetadata.py       # Creates ClickHouse service & ingestion pipeline
â”‚   â””â”€â”€ config.json                     # OpenMetadata service configuration template
â”œâ”€â”€ superset/                           # Apache Superset configuration and assets
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â””â”€â”€ superset_assets.zip         # Exported dashboard and chart definitions
â”‚   â”œâ”€â”€ uploads/                        # Uploaded files for Superset
â”‚   â”œâ”€â”€ fix_import_zip.py               # Script to fix dashboard import ZIP structure
â”‚   â””â”€â”€ superset_config.py              # Superset configuration (auto-import, ClickHouse)
â”œâ”€â”€ docker-compose.yml                  # Defines all services (Airflow, dbt, ClickHouse, Superset, OpenMetadata, Iceberg, MinIO)
â”œâ”€â”€ Dockerfile                          # Docker build for standalone dbt service
â”œâ”€â”€ Dockerfile.airflow                  # Docker build for Airflow services
â”œâ”€â”€ Dockerfile.superset                 # Docker build for Superset with ClickHouse driver
â”œâ”€â”€ README.md                           # Main documentation for Part 3
â””â”€â”€ Star_schema_02.png                  # Star schema diagram
```

---

## ğŸ—„ï¸ Data Governance with Apache Iceberg & OpenMetadata

### Example of added table and column descriptions for fact table 
![OpenMetadata column descriptions](visuals/metadata_cols.png)
### Integrated three tests for data quality:

OpenMetaData tests
![OpenMetaData tests](visuals/openmetadata_tests.png)


---

## ğŸ¦ Roles and Query access in ClickHouse


### Roles are created here:
[Roles_and_Users_creation](https://github.com/LauriLopp/DE_project_2025/tree/main/03_Iceberg_OpenMetadata_Superset/clickhouse-init)

*Note: the access to views is granted in view definition config*

### Access views definition can be found here:

[Create_full_access_view](https://github.com/LauriLopp/DE_project_2025/blob/main/03_Iceberg_OpenMetadata_Superset/dbt/models/views/v_heating_energy_full_access.sql)

[Create_limited_access_view](https://github.com/LauriLopp/DE_project_2025/blob/main/03_Iceberg_OpenMetadata_Superset/dbt/models/views/v_heating_energy_limited_access.sql)

### For testing run these commands:
1. Enter clickhouse-server container:

`docker exec -it de_project2_clickhouse_server bash`

2. Login for full user:
`clickhouse-client --user=user_analyst_full --password=strong_password_full`

3. Run example queries with full analyst user:

```
SELECT
  v.FactKey,
  v.ElectricityPrice,
  v.WC_Temp,
  v.ASHP_Power,
  t.IsHoliday,
  t.Month,
  t.Day,
  t.HourOfDay,
  t.IsWeekend,
  d.Brand,
  d.Model,
  l.DeviceLocation,
  l.PricingRegion
FROM default.v_heating_energy_full_access v
JOIN default.dim_time t ON v.TimeKey = t.TimeKey
JOIN default.dim_device d ON v.DeviceKey = d.DeviceKey
JOIN default.dim_location l ON v.LocationKey = l.LocationKey
order by v.TimeKey desc
LIMIT 10;
```
![Expected result](working_full_query.png)
![Expected result](visuals/working_full_query.png)

```
SELECT * from fact_heatin_energy_usage limit 10;
```
![Expected result](not_working_query.png)
![Expected result](visuals/not_working_query.png)

4. Run queries with limited analyst user
```
SELECT
  v.FactKey,
  v.ElectricityPrice,
  v.WC_Temp,
  v.ASHP_Power,
  t.IsHoliday,
  t.Month,
  t.Day,
  t.HourOfDay,
  t.IsWeekend,
  d.Brand,
  d.Model,
  l.DeviceLocation,
  l.PricingRegion
FROM default.v_heating_energy_limited_access v
JOIN default.dim_time t ON v.TimeKey = t.TimeKey
JOIN default.dim_device d ON v.DeviceKey = d.DeviceKey
JOIN default.dim_location l ON v.LocationKey = l.LocationKey
order by v.TimeKey desc
LIMIT 10;
```
![Expected result](working_limited_query.png)
![Expected result](visuals/working_limited_query.png)
```
SELECT * from fact_heatin_energy_usage limit 10;
```
![Expected result](not_working_query.png)
![Expected result](visuals/not_working_query.png)
---

## ğŸ“ˆ Visualization with Apache Superset

For data visualisation, we connected Clickhouse to Apache Superset in the usual manner.
For visualising our API data, we created a single dashboard. 


---

## ğŸ–¼ï¸ Screenshots & Visuals

Elering Price data in Minio
![Elering Price Minio](visuals/elering_price_data_parquet_minio.png)

Bronze Elering Price in Clickhouse through Minio/Iceberg
![Elering Price Clickhouse](visuals/elering_price_clickhouse.png)

Apache Superset Dashboard
![Apache Superset Dashboard](visuals/dashboard_with_data.png)

---

## ğŸ“ Example Queries & Dashboards

Dashboard & Chart descriptions

Electricity price line-chart

![Electricity Price](visuals/Electricity_price.jpg)

In October and November we experienced "minus-price-day", where the price was negative. See filtered data:
![Electricity Price 0](visuals/Electricity%20Price%200%20in%20Oct-Nov.jpg)


Average Heat-Pump Power vs Outdoor Temperature (5Â°C bins).
Answers Q1 and Q2 â€” â€œHow much energy does the AC need at different outdoor temperatures?â€

![Power vs Outdoor](visuals/average-heat-pump-power-vs-outdoor-temperature-5-c-bins.jpg)

Energy Cost vs Electricity Price Bucket.
Answers Q3 â€” â€œHow much do price fluctuations impact cost?â€

![Cost vs Bucket](visuals/how-much-do-price-fluctuations-impact-cost.jpg)

Energy Use vs Temp Difference (Indoor â€“ Outdoor).
Answers Q1 and Q5 â€” demonstrates heating physics (Temp Delta â†’ Power usage).

![Indoor vs Outdoor](visuals/energy-use-vs-temp-difference-indoor-outdoor.jpg)

---