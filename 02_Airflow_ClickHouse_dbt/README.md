# ‚öôÔ∏è Part 2 ‚Äî Data Pipeline with Airflow, dbt, and ClickHouse

This stage extends the project into a **fully automated data engineering pipeline**, integrating **Airflow**, **dbt**, and **ClickHouse**.  
The goal is to orchestrate data ingestion, transformation, and storage for the analytical data warehouse designed in Part 1.

---

## Overview - how to run the project (setup instructions, environment variables, dependencies)

### üß© Environment & Dependencies
**Required:**
- Docker & Docker Compose  
- Tailscale (for private network connectivity)  
- `.env.local` file containing secret tokens and environment variables

**Optional but helpful:**
- Git  
- A modern web browser (for UI access to Airflow & CloudBeaver)

---

#### üöÄ Setup Instructions

1. **Obtain the `.env.local` file**
   - This file contains environment variables and secret tokens.  
   - Place it **in the same directory** as your `docker-compose.yml`.  
   - ‚ö†Ô∏è It will **not** be in the repository ‚Äî the group will share it manually.

2. **Install and connect to Tailscale**
   - Download and install [Tailscale](https://tailscale.com/download).  
   - Log in with the **Google account credentials provided** or your own (via the invite link).  
   - Ensure you‚Äôre connected to the correct **Tailnet** before proceeding.

3. **Clone the repository**
   ```bash
   git clone https://github.com/LauriLopp/DE_project_2025.git
   cd DE_project_2025/02_Airflow_ClickHouse_dbt
   ```

4. *(Optional)* **Pull latest changes**
   ```bash
   git pull
   ```

5. **Build and start the containers**
   ```bash
   docker-compose up --build -d
   ```
   This will start all services (Airflow, ClickHouse, CloudBeaver, etc.) in detached mode.

6. **Access the Airflow Web UI**
   - Open your browser and go to: [http://localhost:8080](http://localhost:8080)
   - Log in using:
     ```
     Username: airflow
     Password: airflow
     ```

7. **Activate and test a DAG**
   - In Airflow, locate the target DAG.
   - Toggle it **ON**, then trigger a run.
   - Verify the tasks complete successfully.

8. **Access the CloudBeaver UI**
   - Go to: [http://localhost:8978](http://localhost:8978)
   - Click the **gear icon** in the top right to open the login screen.
     ```
     Username: cbadmin
     Password: CloudBeaver1
     ```

9. **Create a ClickHouse connection**
   - Click **+ New Connection** ‚Üí select **ClickHouse**
   - Fill in the connection details:
     ```
     Host: clickhouse-server
     Database: default
     Username: airflow
     Password: supersecret
     ```
   - Check ‚úÖ ‚ÄúSave credentials for all users with access.‚Äù
   - Click **TEST**, then **CREATE.**

10. **Verify database contents**
    - You should now see multiple tables available in the ClickHouse connection.

---

### üß† Notes
- If any service fails to start, run `docker-compose logs <service-name>` for troubleshooting.
- To stop all containers:
  ```bash
  docker-compose down
  ```
- To rebuild everything cleanly:
  ```bash
  docker-compose down -v
  docker-compose up --build -d
  ```

---

---

## üß± Screenshots or visuals of Airflow and dbt DAGs

## DAG listing screenshot
![dag_listing](dag_listing.png)

## DAG details screenshot
![dag_details](dag_details.png)

## DAG continuous ingestion pipeline
![continuous_ingestion_pipeline](continuous_ingestion_pipeline.png)

---

## üóÇÔ∏è Demo queries and explanations
---
## Query 1 ‚Äî Average ASHP Power by Outdoor Temperature Range

We‚Äôre grouping outdoor temperatures into 5¬∞C bins (like -10 to -5, -5 to 0, etc.) and computing:

- The average ASHP (Airsource Head Pump) power within each temperature range  
- The number of data points (hours) in each bin  

```sql
WITH bucketed AS (
  SELECT
    5 * intDiv(toInt32(f.OutdoorTemp), 5) AS bin_start,
    f.ASHP_Power
  FROM default.fact_heating_energy_usage f
  JOIN default.dim_device dd ON f.DeviceKey = dd.DeviceKey
  WHERE f.OutdoorTemp >= -25
    AND f.OutdoorTemp < 30
    AND f.ASHP_Power IS NOT NULL
)
SELECT
  bin_start,
  bin_start + 5 AS bin_end,
  avg(ASHP_Power) AS avg_power_w,
  count() AS hours
FROM bucketed
GROUP BY bin_start
ORDER BY bin_start;
```
We haven‚Äôt run this DAG for long enough to show all temperature bins, though the 5¬∞C‚Äì10¬∞C range already appears with average power data.

![query 1](query%201.png)
---

## Query 2 ‚Äî ML-Ready Energy Dataset

This query prepares ready-to-analyze data for **machine learning** or **statistical modeling**.

It:

- Adds time info (date, hour, weekend flag)  
- Includes indoor/outdoor temps and temperature difference (`TempDelta`)  
- Converts power (W) to energy per hour (kWh)  
- Filters only realistic indoor temps (15‚Äì25¬∞C)  
![query 2](query%202.png)
```sql
SELECT
  dt.FullDate,
  dt.Hour AS HourOfDay,
  if(dt.DayOfWeek IN (6,7), 1, 0) AS IsWeekend,
  f.OutdoorTemp,
  f.IndoorTemp,
  f.IndoorTemp - f.OutdoorTemp AS TempDelta,
  f.ASHP_Power AS power_w,
  f.ASHP_Power / 1000.0 AS energy_kwh_per_hr
FROM default.fact_heating_energy_usage f
JOIN default.dim_time dt ON f.TimeKey = dt.TimeKey
JOIN default.dim_device dd ON dd.DeviceKey = f.DeviceKey
WHERE f.IndoorTemp BETWEEN 15 AND 25
  AND f.OutdoorTemp IS NOT NULL
  AND f.ASHP_Power IS NOT NULL
ORDER BY dt.FullDate, HourOfDay;
```

In the current dataset, only weekend data is available and outdoor temperatures vary little, so energy use appears relatively flat.

---

## Query 3 ‚Äî Power per ¬∞C Difference

Calculates how much power is needed per ¬∞C temperature difference between inside and outside.

- **Numerator:** total power used  
- **Denominator:** total temperature difference (ŒîT = Indoor ‚àí Outdoor)  
- **Result:** average watts per ¬∞C  
![query 3](query%203.png)
```sql
SELECT
  sum(f.ASHP_Power) / nullIf(sum(f.IndoorTemp - f.OutdoorTemp), 0) AS watts_per_C,
  count() AS hours_used
FROM default.fact_heating_energy_usage f
JOIN default.dim_device dd ON dd.DeviceKey = f.DeviceKey
WHERE f.IndoorTemp BETWEEN 20 AND 23
  AND f.OutdoorTemp IS NOT NULL
  AND f.IndoorTemp > f.OutdoorTemp
  AND f.ASHP_Power IS NOT NULL;
```

Originally tested for 19.5‚Äì20.5¬∞C, later adjusted to 20‚Äì23¬∞C due to observed indoor temperatures above 22¬∞C during weekends.

---

## Query 4 ‚Äî Power and Cost by Electricity Price Range

Groups data into 0.05 ‚Ç¨/kWh price ranges to compute:

- Average power used  
- Average price in each bin  
- Total energy (kWh)  
- Total cost (‚Ç¨)  
- Number of hours in each bin  
![query 4](query%204.png)
```sql
SELECT
  0.05 * intDiv(toInt32(f.ElectricityPrice / 0.05), 1) AS price_bin_eur,
  avg(f.ElectricityPrice) AS avg_price_in_bin,
  avg(f.ASHP_Power) AS avg_power_w,
  sum(f.ASHP_Power) / 1000.0 AS energy_kwh,
  sum((f.ASHP_Power / 1000.0) * f.ElectricityPrice) AS bucket_cost,
  count() AS hours
FROM default.fact_heating_energy_usage f
JOIN default.dim_time dt ON f.TimeKey = dt.TimeKey
JOIN default.dim_device dd ON f.DeviceKey = dd.DeviceKey
WHERE f.ElectricityPrice IS NOT NULL
  AND f.ASHP_Power IS NOT NULL
GROUP BY price_bin_eur
ORDER BY price_bin_eur;
```

Three distinct bins appeared during the initial 31-hour data run.

---

## Query 5 ‚Äî Hourly Cost Visualization Dataset

Generates a detailed hourly dataset for visualizing cost behavior.

- Flags peak hours (07:00‚Äì22:00)  
- Flags weekends  
- Calculates power, energy, and cost per hour  
![query 5](query%205.png)
```sql
SELECT
  dt.FullDate,
  dt.Hour AS HourOfDay,
  if(dt.Hour BETWEEN 7 AND 22, 1, 0) AS IsPeakHour,
  if(dt.DayOfWeek IN (6,7), 1, 0) AS IsWeekend,
  0 AS IsHoliday,
  f.ElectricityPrice AS price_eur_per_kwh,
  f.ASHP_Power AS power_w,
  f.ASHP_Power / 1000.0 AS energy_kwh,
  (f.ASHP_Power / 1000.0) * f.ElectricityPrice AS cost_eur
FROM default.fact_heating_energy_usage f
JOIN default.dim_time dt ON f.TimeKey = dt.TimeKey
JOIN default.dim_device dd ON f.DeviceKey = dd.DeviceKey
WHERE f.ASHP_Power IS NOT NULL
  AND f.ElectricityPrice IS NOT NULL
ORDER BY dt.FullDate, HourOfDay;
```

---

## Query 6 ‚Äî Energy and Cost Comparison (Weekday/Weekend, Peak/Off-Peak)

Compares energy use and cost between:

- Weekdays vs. Weekends  
- Peak vs. Off-peak hours  
![query 6](query%206.png)
```sql
SELECT
  multiIf(dt.DayOfWeek IN (6,7), 'Weekend', 'Weekday') AS day_type,
  if(dt.Hour BETWEEN 7 AND 22, 1, 0) AS IsPeakHour,
  sum(f.ASHP_Power) / 1000.0 AS energy_kwh,
  sum((f.ASHP_Power / 1000.0) * f.ElectricityPrice) AS cost_eur,
  avg(f.ElectricityPrice) AS avg_price_eur_per_kwh,
  count() AS hours
FROM default.fact_heating_energy_usage f
JOIN default.dim_time dt ON f.TimeKey = dt.TimeKey
JOIN default.dim_device dd ON f.DeviceKey = dd.DeviceKey
WHERE f.ASHP_Power IS NOT NULL
  AND f.ElectricityPrice IS NOT NULL
GROUP BY day_type, IsPeakHour
ORDER BY day_type, IsPeakHour DESC;
```

In the current dataset, all 23 hours of recorded consumption were during off-peak weekend hours.

---

## Query 7 ‚Äî Energy by Month and Temperature Range

Groups energy usage by **month** and **5¬∞C temperature ranges** to examine seasonal variations.
![query 7](query%207.png)
```sql
WITH bucketed AS (
  SELECT
    dt.Year,
    dt.Month,
    5 * intDiv(toInt32(f.OutdoorTemp), 5) AS bin_start,
    f.ASHP_Power
  FROM default.fact_heating_energy_usage f
  JOIN default.dim_time dt ON f.TimeKey = dt.TimeKey
  JOIN default.dim_device dd ON f.DeviceKey = dd.DeviceKey
  WHERE f.OutdoorTemp >= -25
    AND f.OutdoorTemp < 30
    AND f.ASHP_Power IS NOT NULL
)
SELECT
  Year,
  Month,
  bin_start,
  bin_start + 5 AS bin_end,
  sum(ASHP_Power) / 1000.0 AS energy_kwh,
  count() AS hours
FROM bucketed
GROUP BY Year, Month, bin_start
ORDER BY Year, Month, bin_start;
```

Currently, the dataset includes **November only**, with 31 total recorded hours.

---

## Query 8 ‚Äî Hours Below Minimum Rated Power

Shows how many hours per day the ASHP operated below its **minimum rated power**, which may indicate:

- System idling  
- Inefficiency  
- Underperformance  
![query 8](query%208.png)
```sql
SELECT
  dt.Year,
  dt.Month,
  dt.Day,
  count() AS hours_below_min
FROM default.fact_heating_energy_usage f
JOIN default.dim_time dt ON f.TimeKey = dt.TimeKey
JOIN default.dim_device dd ON f.DeviceKey = dd.DeviceKey
WHERE f.ASHP_Power IS NOT NULL
  AND dd.MinPower IS NOT NULL
  AND f.ASHP_Power < dd.MinPower
GROUP BY dt.Year, dt.Month, dt.Day
ORDER BY dt.Year, dt.Month, dt.Day;
```

This result covers two days and 31 total hours of recorded data.

---
